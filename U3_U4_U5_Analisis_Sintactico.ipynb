{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgWSrerPY8il"
      },
      "source": [
        "# Ejercicios Prácticos: Análisis Sintáctico\n",
        "## Procesadores del Lenguaje - Nivel Universitario Introductorio\n",
        "\n",
        "Este cuaderno contiene ejercicios prácticos sobre análisis sintáctico.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wPiIBffY8im"
      },
      "source": [
        "---\n",
        "## Ejercicio 1: Identificación de Elementos de una Gramática\n",
        "\n",
        "Gramática para expresiones booleanas:\n",
        "```\n",
        "E -> E or T | T\n",
        "T -> T and F | F\n",
        "F -> not F | true | false | ( E )\n",
        "```\n",
        "\n",
        "**Tarea:** Identifica terminales, no-terminales y símbolo inicial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LxxoXASY8in",
        "outputId": "cdba9ac1-e1ff-45ee-c3e8-798e11c33c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Terminales: ['or', 'and', 'not', 'true', 'false', '(', ')']\n",
            "No-terminales: ['E', 'T', 'F']\n",
            "Símbolo inicial: E\n"
          ]
        }
      ],
      "source": [
        "# SOLUCIÓN:\n",
        "terminales = ['or', 'and', 'not', 'true', 'false', '(', ')']\n",
        "no_terminales = ['E', 'T', 'F']\n",
        "simbolo_inicial = 'E'\n",
        "\n",
        "print(f\"Terminales: {terminales}\")\n",
        "print(f\"No-terminales: {no_terminales}\")\n",
        "print(f\"Símbolo inicial: {simbolo_inicial}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvwEbGszY8in"
      },
      "source": [
        "---\n",
        "## Ejercicio 2: Tokenizador Básico\n",
        "\n",
        "**Tarea:** Implementa un tokenizador para expresiones aritméticas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq86FRS1Y8io",
        "outputId": "cec9832e-f5fa-4f03-fbf5-666b204d8970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('NUMERO', '3'), ('SUMA', '+'), ('NUMERO', '4'), ('MULT', '*'), ('NUMERO', '2')]\n",
            "[('LPAREN', '('), ('NUMERO', '10'), ('RESTA', '-'), ('NUMERO', '5'), ('RPAREN', ')'), ('DIV', '/'), ('NUMERO', '2')]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def tokenizar(expresion):\n",
        "    \"\"\"\n",
        "    Tokeniza una expresión aritmética.\n",
        "    Retorna: lista de tuplas (tipo, valor)\n",
        "    \"\"\"\n",
        "    patrones = [\n",
        "        ('NUMERO', r'\\d+'),\n",
        "        ('SUMA', r'\\+'),\n",
        "        ('RESTA', r'-'),\n",
        "        ('MULT', r'\\*'),\n",
        "        ('DIV', r'/'),\n",
        "        ('LPAREN', r'\\('),\n",
        "        ('RPAREN', r'\\)'),\n",
        "        ('ESPACIO', r'\\s+'),\n",
        "    ]\n",
        "\n",
        "    # Combinar todos los patrones\n",
        "    regex = '|'.join(f'(?P<{nombre}>{patron})' for nombre, patron in patrones)\n",
        "\n",
        "    tokens = []\n",
        "    for match in re.finditer(regex, expresion):\n",
        "        tipo = match.lastgroup\n",
        "        valor = match.group()\n",
        "        if tipo != 'ESPACIO':  # Ignorar espacios\n",
        "            tokens.append((tipo, valor))\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Pruebas\n",
        "print(tokenizar(\"3 + 4 * 2\"))\n",
        "print(tokenizar(\"(10 - 5) / 2\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 3: Clases para AST\n",
        "\n",
        "**Tarea:** Define las clases para representar un AST."
      ],
      "metadata": {
        "id": "FYIY12MagTvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NodoAST:\n",
        "    \"\"\"Clase base para nodos del AST\"\"\"\n",
        "    pass\n",
        "\n",
        "class Numero(NodoAST):\n",
        "    def __init__(self, valor):\n",
        "        self.valor = int(valor)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Numero({self.valor})\"\n",
        "\n",
        "class OperacionBinaria(NodoAST):\n",
        "    def __init__(self, izquierda, operador, derecha):\n",
        "        self.izquierda = izquierda\n",
        "        self.operador = operador\n",
        "        self.derecha = derecha\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"OpBin({self.izquierda} {self.operador} {self.derecha})\"\n",
        "\n",
        "# Ejemplo de uso\n",
        "ast = OperacionBinaria(\n",
        "    Numero(3),\n",
        "    '+',\n",
        "    OperacionBinaria(Numero(4), '*', Numero(2))\n",
        ")\n",
        "print(f\"AST para '3 + 4 * 2': {ast}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzxaJO0agU2G",
        "outputId": "1e33e15e-edb3-406d-ce8c-5c572a712023"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AST para '3 + 4 * 2': OpBin(Numero(3) + OpBin(Numero(4) * Numero(2)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzvjdxbqY8io"
      },
      "source": [
        "---\n",
        "## Ejercicio 4: Parser de Descenso Recursivo\n",
        "\n",
        "Gramática sin recursión izquierda:\n",
        "```\n",
        "E -> T E'\n",
        "E' -> + T E' | ε\n",
        "T -> F T'\n",
        "T' -> * F T' | ε\n",
        "F -> ( E ) | numero\n",
        "```\n",
        "\n",
        "**Tarea:** Implementa el parser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6G_hjLLY8io",
        "outputId": "47a410e0-a471-4d43-8a2d-69f16d8cbfdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expresión: 3 + 4 * 2\n",
            "AST: OpBin(Numero(3) + OpBin(Numero(4) * Numero(2)))\n"
          ]
        }
      ],
      "source": [
        "class Parser:\n",
        "    def __init__(self, tokens):\n",
        "        self.tokens = tokens\n",
        "        self.pos = 0\n",
        "\n",
        "    def token_actual(self):\n",
        "        if self.pos < len(self.tokens):\n",
        "            return self.tokens[self.pos]\n",
        "        return None\n",
        "\n",
        "    def consumir(self, tipo_esperado):\n",
        "        token = self.token_actual()\n",
        "        if token and token[0] == tipo_esperado:\n",
        "            self.pos += 1\n",
        "            return token\n",
        "        raise SyntaxError(f\"Se esperaba {tipo_esperado}, se encontró {token}\")\n",
        "\n",
        "    def parse_E(self):\n",
        "        \"\"\"E -> T E'\"\"\"\n",
        "        izquierda = self.parse_T()\n",
        "        return self.parse_E_prima(izquierda)\n",
        "\n",
        "    def parse_E_prima(self, izquierda):\n",
        "        \"\"\"E' -> + T E' | ε\"\"\"\n",
        "        token = self.token_actual()\n",
        "        if token and token[0] == 'SUMA':\n",
        "            self.consumir('SUMA')\n",
        "            derecha = self.parse_T()\n",
        "            nodo = OperacionBinaria(izquierda, '+', derecha)\n",
        "            return self.parse_E_prima(nodo)\n",
        "        elif token and token[0] == 'RESTA':\n",
        "            self.consumir('RESTA')\n",
        "            derecha = self.parse_T()\n",
        "            nodo = OperacionBinaria(izquierda, '-', derecha)\n",
        "            return self.parse_E_prima(nodo)\n",
        "        return izquierda  # ε\n",
        "\n",
        "    def parse_T(self):\n",
        "        \"\"\"T -> F T'\"\"\"\n",
        "        izquierda = self.parse_F()\n",
        "        return self.parse_T_prima(izquierda)\n",
        "\n",
        "    def parse_T_prima(self, izquierda):\n",
        "        \"\"\"T' -> * F T' | ε\"\"\"\n",
        "        token = self.token_actual()\n",
        "        if token and token[0] == 'MULT':\n",
        "            self.consumir('MULT')\n",
        "            derecha = self.parse_F()\n",
        "            nodo = OperacionBinaria(izquierda, '*', derecha)\n",
        "            return self.parse_T_prima(nodo)\n",
        "        elif token and token[0] == 'DIV':\n",
        "            self.consumir('DIV')\n",
        "            derecha = self.parse_F()\n",
        "            nodo = OperacionBinaria(izquierda, '/', derecha)\n",
        "            return self.parse_T_prima(nodo)\n",
        "        return izquierda  # ε\n",
        "\n",
        "    def parse_F(self):\n",
        "        \"\"\"F -> ( E ) | numero\"\"\"\n",
        "        token = self.token_actual()\n",
        "        if token[0] == 'LPAREN':\n",
        "            self.consumir('LPAREN')\n",
        "            nodo = self.parse_E()\n",
        "            self.consumir('RPAREN')\n",
        "            return nodo\n",
        "        elif token[0] == 'NUMERO':\n",
        "            self.consumir('NUMERO')\n",
        "            return Numero(token[1])\n",
        "        else:\n",
        "            raise SyntaxError(f\"Token inesperado: {token}\")\n",
        "\n",
        "    def parse(self):\n",
        "        ast = self.parse_E()\n",
        "        if self.pos != len(self.tokens):\n",
        "            raise SyntaxError(\"Tokens adicionales después del final\")\n",
        "        return ast\n",
        "\n",
        "# Prueba\n",
        "expresion = \"3 + 4 * 2\"\n",
        "tokens = tokenizar(expresion)\n",
        "parser = Parser(tokens)\n",
        "ast = parser.parse()\n",
        "print(f\"Expresión: {expresion}\")\n",
        "print(f\"AST: {ast}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Esto tiene formato de código\n",
        "```\n",
        "\n",
        "## Ejercicio 5: Evaluador de Expresiones\n",
        "\n",
        "**Tarea:** Implementa un evaluador que calcule el resultado."
      ],
      "metadata": {
        "id": "U7-Uo-66fuLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluar(nodo):\n",
        "    \"\"\"Evalúa un AST y retorna el resultado.\"\"\"\n",
        "    if isinstance(nodo, Numero):\n",
        "        return nodo.valor\n",
        "    elif isinstance(nodo, OperacionBinaria):\n",
        "        izq = evaluar(nodo.izquierda)\n",
        "        der = evaluar(nodo.derecha)\n",
        "\n",
        "        if nodo.operador == '+':\n",
        "            return izq + der\n",
        "        elif nodo.operador == '-':\n",
        "            return izq - der\n",
        "        elif nodo.operador == '*':\n",
        "            return izq * der\n",
        "        elif nodo.operador == '/':\n",
        "            return izq / der\n",
        "\n",
        "    raise ValueError(f\"Nodo desconocido: {type(nodo)}\")\n",
        "\n",
        "# Pruebas\n",
        "expresiones = [\n",
        "    \"3 + 4\",\n",
        "    \"10 - 5 * 2\",\n",
        "    \"(4 + 5) * 3\",\n",
        "    \"100 / (2 + 3)\"\n",
        "]\n",
        "\n",
        "for expr in expresiones:\n",
        "    tokens = tokenizar(expr)\n",
        "    parser = Parser(tokens)\n",
        "    ast = parser.parse()\n",
        "    resultado = evaluar(ast)\n",
        "    print(f\"{expr} = {resultado}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGPQ26DMfyLa",
        "outputId": "c7531e67-a060-43df-a602-f003e6baaf00"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 + 4 = 7\n",
            "10 - 5 * 2 = 0\n",
            "(4 + 5) * 3 = 27\n",
            "100 / (2 + 3) = 20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvKV110PY8ip"
      },
      "source": [
        "---\n",
        "## Ejercicio 6: Calculadora Completa\n",
        "\n",
        "**Tarea:** Integra todo en un sistema completo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nbwr8kPY8ip",
        "outputId": "107f44db-de98-4390-fd2c-04ae5e5847f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculadora Aritmética\n",
            "Escribe 'salir' para terminar\n",
            "\n",
            "2 + 2 = 4\n",
            "10 * (5 + 3) = 80\n",
            "100 / 4 - 5 = 20.0\n",
            "(8 - 3) * (4 + 2) = 30\n"
          ]
        }
      ],
      "source": [
        "def calcular(expresion):\n",
        "    \"\"\"Función todo-en-uno: tokenizar -> parsear -> evaluar\"\"\"\n",
        "    try:\n",
        "        tokens = tokenizar(expresion)\n",
        "        parser = Parser(tokens)\n",
        "        ast = parser.parse()\n",
        "        resultado = evaluar(ast)\n",
        "        return resultado\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Modo interactivo\n",
        "print(\"Calculadora Aritmética\")\n",
        "print(\"Escribe 'salir' para terminar\\n\")\n",
        "\n",
        "# Descomenta para modo interactivo:\n",
        "# while True:\n",
        "#     expresion = input(\">>> \").strip()\n",
        "#     if expresion.lower() == 'salir':\n",
        "#         break\n",
        "#     if expresion:\n",
        "#         resultado = calcular(expresion)\n",
        "#         print(f\"  = {resultado}\\n\")\n",
        "\n",
        "# Pruebas automáticas\n",
        "pruebas = [\n",
        "    \"2 + 2\",\n",
        "    \"10 * (5 + 3)\",\n",
        "    \"100 / 4 - 5\",\n",
        "    \"(8 - 3) * (4 + 2)\"\n",
        "]\n",
        "\n",
        "for expr in pruebas:\n",
        "    print(f\"{expr} = {calcular(expr)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALm0zodDV7ZX"
      },
      "source": [
        "## Ejercicio 7: Detección de Ambigüedad\n",
        "\n",
        "**Objetivo:** Identificar gramáticas ambiguas y entender sus problemas.\n",
        "\n",
        "Gramática ambigua:\n",
        "```\n",
        "E -> E + E | E * E | ( E ) | id\n",
        "```\n",
        "\n",
        "**Tarea:** Demuestra que es ambigua generando dos árboles diferentes para: **`id + id * id`**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1PwzRXQV7ZX",
        "outputId": "26446da9-46ba-4519-e8db-3749f07fffbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DEMOSTRACIÓN DE AMBIGÜEDAD: id + id * id\n",
            "======================================================================\n",
            "\n",
            "INTERPRETACIÓN 1: (id + id) * id\n",
            "\n",
            "        E\n",
            "       /|\n",
            "      E * E\n",
            "     /|\\  |\n",
            "    E+E  id\n",
            "    | |\n",
            "   id id\n",
            "\n",
            "Resultado si id=2: (2 + 2) * 2 = 8\n",
            "\n",
            "INTERPRETACIÓN 2: id + (id * id)\n",
            "\n",
            "        E\n",
            "       /|\n",
            "      E + E\n",
            "      |  /|\n",
            "     id E*E\n",
            "        | |\n",
            "       id id\n",
            "\n",
            "Resultado si id=2: 2 + (2 * 2) = 6\n",
            "\n",
            "======================================================================\n",
            "CONCLUSIÓN:\n",
            "======================================================================\n",
            "✓ La gramática es AMBIGUA porque la misma cadena tiene dos\n",
            "  árboles de derivación diferentes con significados distintos.\n",
            "✓ Esto es INACEPTABLE en lenguajes de programación.\n",
            "\n",
            "\n",
            "¿Cómo se resuelve esta ambigüedad?\n",
            "1. Reescribir la gramática con niveles de precedencia (E, T, F)\n",
            "2. Usar reglas de precedencia en el parser\n",
            "3. Forzar asociatividad (izquierda o derecha)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:7: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:7: SyntaxWarning: invalid escape sequence '\\ '\n",
            "/tmp/ipython-input-2855246149.py:7: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  /|\\  |\n"
          ]
        }
      ],
      "source": [
        "# Representa los árboles como listas de tuplas (nivel, nodo)\n",
        "\n",
        "# Interpretación 1: (id + id) * id  [SUMA primero]\n",
        "arbol_interpretacion_1 = \"\"\"\n",
        "        E\n",
        "       /|\\n      E * E\n",
        "     /|\\  |\n",
        "    E+E  id\n",
        "    | |\n",
        "   id id\n",
        "\"\"\"\n",
        "\n",
        "# Interpretación 2: id + (id * id)  [MULTIPLICACIÓN primero]\n",
        "arbol_interpretacion_2 = \"\"\"\n",
        "        E\n",
        "       /|\\n      E + E\n",
        "      |  /|\\n     id E*E\n",
        "        | |\n",
        "       id id\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"DEMOSTRACIÓN DE AMBIGÜEDAD: id + id * id\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nINTERPRETACIÓN 1: (id + id) * id\")\n",
        "print(arbol_interpretacion_1)\n",
        "print(\"Resultado si id=2: (2 + 2) * 2 = 8\")\n",
        "\n",
        "print(\"\\nINTERPRETACIÓN 2: id + (id * id)\")\n",
        "print(arbol_interpretacion_2)\n",
        "print(\"Resultado si id=2: 2 + (2 * 2) = 6\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONCLUSIÓN:\")\n",
        "print(\"=\"*70)\n",
        "print(\"✓ La gramática es AMBIGUA porque la misma cadena tiene dos\")\n",
        "print(\"  árboles de derivación diferentes con significados distintos.\")\n",
        "print(\"✓ Esto es INACEPTABLE en lenguajes de programación.\")\n",
        "\n",
        "# PREGUNTA DE REFLEXIÓN:\n",
        "respuesta = \"\"\"\n",
        "¿Cómo se resuelve esta ambigüedad?\n",
        "1. Reescribir la gramática con niveles de precedencia (E, T, F)\n",
        "2. Usar reglas de precedencia en el parser\n",
        "3. Forzar asociatividad (izquierda o derecha)\n",
        "\"\"\"\n",
        "print(\"\\n\" + respuesta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snphDlyEV7ZX"
      },
      "source": [
        "## Ejercicio 8: Árbol de Derivación vs AST\n",
        "\n",
        "**Objetivo:** Diferenciar entre parse tree (derivación) y AST (abstracto).\n",
        "\n",
        "Para la expresión: **`3 + 4 * 5`**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKrMgIz1V7ZX",
        "outputId": "aedfd456-eb52-4ec2-d168-82e93015ecf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "COMPARACIÓN: Parse Tree vs AST\n",
            "======================================================================\n",
            "\n",
            "Árbol de Derivación (Parse Tree):\n",
            "Muestra CÓMO se aplicó la gramática\n",
            "\n",
            "            E\n",
            "           /|\n",
            "          E + T\n",
            "          |  /|\n",
            "          T T * F\n",
            "          | |   |\n",
            "          F F   5\n",
            "          | |\n",
            "          3 4\n",
            "\n",
            "Características:\n",
            "- Incluye TODOS los no-terminales (E, T, F)\n",
            "- Muestra la estructura gramatical completa\n",
            "- Útil para verificar que la derivación es correcta\n",
            "\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Árbol de Sintaxis Abstracto (AST):\n",
            "Captura solo la ESTRUCTURA ESENCIAL\n",
            "\n",
            "        +\n",
            "       / \n",
            "      3   *\n",
            "         / \n",
            "        4   5\n",
            "\n",
            "Características:\n",
            "- OMITE no-terminales intermedios (E, T, F)\n",
            "- Solo operadores y operandos\n",
            "- Más limpio y fácil de procesar\n",
            "- Usado por fases posteriores del compilador\n",
            "\n",
            "\n",
            "======================================================================\n",
            "AST como objeto Python:\n",
            "  (3 + (4 * 5))\n",
            "\n",
            "✓ El AST es la representación preferida para análisis semántico\n",
            "  y generación de código.\n"
          ]
        }
      ],
      "source": [
        "# Árbol de Derivación (Parse Tree) - muestra TODA la derivación\n",
        "parse_tree = \"\"\"\n",
        "Árbol de Derivación (Parse Tree):\n",
        "Muestra CÓMO se aplicó la gramática\n",
        "\n",
        "            E\n",
        "           /|\\n          E + T\n",
        "          |  /|\\n          T T * F\n",
        "          | |   |\n",
        "          F F   5\n",
        "          | |\n",
        "          3 4\n",
        "\n",
        "Características:\n",
        "- Incluye TODOS los no-terminales (E, T, F)\n",
        "- Muestra la estructura gramatical completa\n",
        "- Útil para verificar que la derivación es correcta\n",
        "\"\"\"\n",
        "\n",
        "# Árbol de Sintaxis Abstracto (AST) - solo lo esencial\n",
        "ast_tree = \"\"\"\n",
        "Árbol de Sintaxis Abstracto (AST):\n",
        "Captura solo la ESTRUCTURA ESENCIAL\n",
        "\n",
        "        +\n",
        "       / \\n      3   *\n",
        "         / \\n        4   5\n",
        "\n",
        "Características:\n",
        "- OMITE no-terminales intermedios (E, T, F)\n",
        "- Solo operadores y operandos\n",
        "- Más limpio y fácil de procesar\n",
        "- Usado por fases posteriores del compilador\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"COMPARACIÓN: Parse Tree vs AST\")\n",
        "print(\"=\"*70)\n",
        "print(parse_tree)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(ast_tree)\n",
        "\n",
        "# Implementación de clases para AST\n",
        "class NodoAST:\n",
        "    pass\n",
        "\n",
        "class Numero(NodoAST):\n",
        "    def __init__(self, valor):\n",
        "        self.valor = valor\n",
        "    def __repr__(self):\n",
        "        return str(self.valor)\n",
        "\n",
        "class OpBinaria(NodoAST):\n",
        "    def __init__(self, izq, op, der):\n",
        "        self.izq = izq\n",
        "        self.op = op\n",
        "        self.der = der\n",
        "    def __repr__(self):\n",
        "        return f\"({self.izq} {self.op} {self.der})\"\n",
        "\n",
        "# Construye el AST para 3 + 4 * 5\n",
        "ast = OpBinaria(\n",
        "    Numero(3),\n",
        "    '+',\n",
        "    OpBinaria(Numero(4), '*', Numero(5))\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"AST como objeto Python:\")\n",
        "print(f\"  {ast}\")\n",
        "print(\"\\n✓ El AST es la representación preferida para análisis semántico\")\n",
        "print(\"  y generación de código.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-36UNgRV7ZY"
      },
      "source": [
        "## Ejercicio 9: Transformación - Eliminación de Recursión Izquierda\n",
        "\n",
        "**Objetivo:** Aprender a transformar gramáticas para análisis descendente.\n",
        "\n",
        "**Problema:** Los parsers descendentes no pueden manejar recursión izquierda.\n",
        "\n",
        "Gramática CON recursión izquierda:\n",
        "```\n",
        "E -> E + T | T\n",
        "T -> T * F | F\n",
        "F -> ( E ) | id\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KqxsFXdV7ZY",
        "outputId": "6d44ac41-8e01-4122-f72c-80a0e1946897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ELIMINACIÓN DE RECURSIÓN IZQUIERDA\n",
            "======================================================================\n",
            "\n",
            "GRAMÁTICA ORIGINAL (con recursión izquierda):\n",
            "  E -> E + T\n",
            "  E -> T\n",
            "  T -> T * F\n",
            "  T -> F\n",
            "  F -> ( E )\n",
            "  F -> id\n",
            "\n",
            "⚠️  PROBLEMA: E -> E + T y T -> T * F causan recursión infinita\n",
            "    en parsers descendentes.\n",
            "\n",
            "GRAMÁTICA TRANSFORMADA (sin recursión izquierda):\n",
            "  E -> T E'\n",
            "  E' -> + T E'\n",
            "  E' -> ε\n",
            "  T -> F T'\n",
            "  T' -> * F T'\n",
            "  T' -> ε\n",
            "  F -> ( E )\n",
            "  F -> id\n",
            "\n",
            "✓ Ahora la gramática NO tiene recursión izquierda\n",
            "✓ Puede ser usada por un parser de descenso recursivo\n"
          ]
        }
      ],
      "source": [
        "# Algoritmo para eliminar recursión izquierda:\n",
        "# Si tenemos: A -> A α | β\n",
        "# Transformar a: A -> β A'\n",
        "#                A' -> α A' | ε\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ELIMINACIÓN DE RECURSIÓN IZQUIERDA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nGRAMÁTICA ORIGINAL (con recursión izquierda):\")\n",
        "gramatica_original = {\n",
        "    'E': ['E + T', 'T'],\n",
        "    'T': ['T * F', 'F'],\n",
        "    'F': ['( E )', 'id']\n",
        "}\n",
        "\n",
        "for nt, prods in gramatica_original.items():\n",
        "    for prod in prods:\n",
        "        print(f\"  {nt} -> {prod}\")\n",
        "\n",
        "print(\"\\n⚠️  PROBLEMA: E -> E + T y T -> T * F causan recursión infinita\")\n",
        "print(\"    en parsers descendentes.\\n\")\n",
        "\n",
        "# COMPLETA LA GRAMÁTICA TRANSFORMADA:\n",
        "print(\"GRAMÁTICA TRANSFORMADA (sin recursión izquierda):\")\n",
        "gramatica_transformada = {\n",
        "    'E': [],      # COMPLETA: ['T E\\'']\n",
        "    \"E'\": [],     # COMPLETA: ['+ T E\\'', 'ε']\n",
        "    'T': [],      # COMPLETA: ['F T\\'']\n",
        "    \"T'\": [],     # COMPLETA: ['* F T\\'', 'ε']\n",
        "    'F': ['( E )', 'id']\n",
        "}\n",
        "\n",
        "# SOLUCIÓN:\n",
        "solucion = {\n",
        "    'E': ['T E\\''],\n",
        "    \"E'\": ['+ T E\\'', 'ε'],\n",
        "    'T': ['F T\\''],\n",
        "    \"T'\": ['* F T\\'', 'ε'],\n",
        "    'F': ['( E )', 'id']\n",
        "}\n",
        "\n",
        "for nt, prods in solucion.items():\n",
        "    for prod in prods:\n",
        "        print(f\"  {nt} -> {prod}\")\n",
        "\n",
        "print(\"\\n✓ Ahora la gramática NO tiene recursión izquierda\")\n",
        "print(\"✓ Puede ser usada por un parser de descenso recursivo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLO1nKWmV7ZY"
      },
      "source": [
        "\n",
        "## Ejercicio 10: Implementación de Tokenizador Robusto\n",
        "\n",
        "**Objetivo:** Crear un tokenizador completo para expresiones aritméticas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5b34v3iV7ZY",
        "outputId": "1cb4f671-93ca-4821-ed0c-79d4e74fb65d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TOKENIZADOR DE EXPRESIONES ARITMÉTICAS\n",
            "======================================================================\n",
            "\n",
            "Expresión: 3 + 4\n",
            "Tokens:\n",
            "  NUMERO     '3    ' (pos 0)\n",
            "  SUMA       '+    ' (pos 2)\n",
            "  NUMERO     '4    ' (pos 4)\n",
            "\n",
            "Expresión: 10 * (2 + 5)\n",
            "Tokens:\n",
            "  NUMERO     '10   ' (pos 0)\n",
            "  MULT       '*    ' (pos 3)\n",
            "  LPAREN     '(    ' (pos 5)\n",
            "  NUMERO     '2    ' (pos 6)\n",
            "  SUMA       '+    ' (pos 8)\n",
            "  NUMERO     '5    ' (pos 10)\n",
            "  RPAREN     ')    ' (pos 11)\n",
            "\n",
            "Expresión: x + y * 2\n",
            "Tokens:\n",
            "  ID         'x    ' (pos 0)\n",
            "  SUMA       '+    ' (pos 2)\n",
            "  ID         'y    ' (pos 4)\n",
            "  MULT       '*    ' (pos 6)\n",
            "  NUMERO     '2    ' (pos 8)\n",
            "\n",
            "Expresión: 3.14 * radio ^ 2\n",
            "Tokens:\n",
            "  NUMERO     '3.14 ' (pos 0)\n",
            "  MULT       '*    ' (pos 5)\n",
            "  ID         'radio' (pos 7)\n",
            "  POT        '^    ' (pos 13)\n",
            "  NUMERO     '2    ' (pos 15)\n",
            "\n",
            "✓ El tokenizador es el primer paso del análisis sintáctico\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def tokenizar(expresion):\n",
        "    \"\"\"\n",
        "    Tokeniza una expresión aritmética.\n",
        "    Retorna: lista de tuplas (tipo, valor, posicion)\n",
        "    \"\"\"\n",
        "    # Define los patrones de tokens (orden importa!)\n",
        "    patrones = [\n",
        "        ('NUMERO',   r'\\d+(\\.\\d+)?'),  # Enteros y decimales\n",
        "        ('ID',       r'[a-zA-Z_][a-zA-Z0-9_]*'),  # Identificadores\n",
        "        ('SUMA',     r'\\+'),\n",
        "        ('RESTA',    r'-'),\n",
        "        ('MULT',     r'\\*'),\n",
        "        ('DIV',      r'/'),\n",
        "        ('POT',      r'\\^'),\n",
        "        ('LPAREN',   r'\\('),\n",
        "        ('RPAREN',   r'\\)'),\n",
        "        ('ESPACIO',  r'\\s+'),\n",
        "        ('ERROR',    r'.'),  # Cualquier carácter no reconocido\n",
        "    ]\n",
        "\n",
        "    # Combinar todos los patrones en una sola regex\n",
        "    regex_completa = '|'.join(f'(?P<{nombre}>{patron})' for nombre, patron in patrones)\n",
        "\n",
        "    tokens = []\n",
        "    for match in re.finditer(regex_completa, expresion):\n",
        "        tipo = match.lastgroup\n",
        "        valor = match.group()\n",
        "        posicion = match.start()\n",
        "\n",
        "        if tipo == 'ESPACIO':\n",
        "            continue  # Ignorar espacios\n",
        "        elif tipo == 'ERROR':\n",
        "            raise SyntaxError(f\"Carácter inválido '{valor}' en posición {posicion}\")\n",
        "\n",
        "        tokens.append((tipo, valor, posicion))\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Pruebas\n",
        "print(\"=\"*70)\n",
        "print(\"TOKENIZADOR DE EXPRESIONES ARITMÉTICAS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "expresiones_prueba = [\n",
        "    \"3 + 4\",\n",
        "    \"10 * (2 + 5)\",\n",
        "    \"x + y * 2\",\n",
        "    \"3.14 * radio ^ 2\",\n",
        "]\n",
        "\n",
        "for expr in expresiones_prueba:\n",
        "    print(f\"\\nExpresión: {expr}\")\n",
        "    tokens = tokenizar(expr)\n",
        "    print(\"Tokens:\")\n",
        "    for tipo, valor, pos in tokens:\n",
        "        print(f\"  {tipo:10} '{valor:5}' (pos {pos})\")\n",
        "\n",
        "print(\"\\n✓ El tokenizador es el primer paso del análisis sintáctico\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J8E0_EcV7ZZ"
      },
      "source": [
        "## Ejercicio 11: Parser de Descenso Recursivo Completo\n",
        "\n",
        "**Objetivo:** Implementar un parser descendente con precedencia de operadores.\n",
        "\n",
        "Gramática (sin recursión izquierda):\n",
        "```\n",
        "E -> T E'\n",
        "E' -> + T E' | - T E' | ε\n",
        "T -> F T'\n",
        "T' -> * F T' | / F T' | ε\n",
        "F -> ( E ) | numero | id\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgF74tjbV7ZZ",
        "outputId": "f278a36a-5d87-46fc-d99a-d8bb4d0d4c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PARSER DE DESCENSO RECURSIVO\n",
            "======================================================================\n",
            "\n",
            "Expresión: 3 + 4\n",
            "AST: (3 + 4)\n",
            "Resultado: 7\n",
            "✓ Parsing exitoso\n",
            "\n",
            "Expresión: 10 * 2 + 5\n",
            "AST: ((10 * 2) + 5)\n",
            "Resultado: 25\n",
            "✓ Parsing exitoso\n",
            "\n",
            "Expresión: (4 + 5) * 3\n",
            "AST: ((4 + 5) * 3)\n",
            "Resultado: 27\n",
            "✓ Parsing exitoso\n",
            "\n",
            "Expresión: x + y * 2\n",
            "Variables: {'x': 5, 'y': 3}\n",
            "AST: (x + (y * 2))\n",
            "Resultado: 11\n",
            "✓ Parsing exitoso\n",
            "\n",
            "======================================================================\n",
            "✓ El parser descendente construye el AST de arriba hacia abajo\n"
          ]
        }
      ],
      "source": [
        "# Clases para el AST\n",
        "class NodoAST:\n",
        "    pass\n",
        "\n",
        "class Numero(NodoAST):\n",
        "    def __init__(self, valor):\n",
        "        self.valor = float(valor) if '.' in str(valor) else int(valor)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{self.valor}\"\n",
        "\n",
        "    def evaluar(self, variables=None):\n",
        "        return self.valor\n",
        "\n",
        "class Variable(NodoAST):\n",
        "    def __init__(self, nombre):\n",
        "        self.nombre = nombre\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.nombre\n",
        "\n",
        "    def evaluar(self, variables=None):\n",
        "        if variables and self.nombre in variables:\n",
        "            return variables[self.nombre]\n",
        "        raise NameError(f\"Variable '{self.nombre}' no definida\")\n",
        "\n",
        "class OperacionBinaria(NodoAST):\n",
        "    def __init__(self, izquierda, operador, derecha):\n",
        "        self.izquierda = izquierda\n",
        "        self.operador = operador\n",
        "        self.derecha = derecha\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"({self.izquierda} {self.operador} {self.derecha})\"\n",
        "\n",
        "    def evaluar(self, variables=None):\n",
        "        izq = self.izquierda.evaluar(variables)\n",
        "        der = self.derecha.evaluar(variables)\n",
        "\n",
        "        if self.operador == '+':\n",
        "            return izq + der\n",
        "        elif self.operador == '-':\n",
        "            return izq - der\n",
        "        elif self.operador == '*':\n",
        "            return izq * der\n",
        "        elif self.operador == '/':\n",
        "            if der == 0:\n",
        "                raise ZeroDivisionError(\"División por cero\")\n",
        "            return izq / der\n",
        "        elif self.operador == '^':\n",
        "            return izq ** der\n",
        "\n",
        "# Parser de Descenso Recursivo\n",
        "class ParserDescensoRecursivo:\n",
        "    def __init__(self, tokens):\n",
        "        self.tokens = tokens\n",
        "        self.pos = 0\n",
        "\n",
        "    def token_actual(self):\n",
        "        \"\"\"Retorna el token actual sin consumirlo.\"\"\"\n",
        "        if self.pos < len(self.tokens):\n",
        "            return self.tokens[self.pos]\n",
        "        return None\n",
        "\n",
        "    def consumir(self, tipo_esperado):\n",
        "        \"\"\"Consume un token del tipo esperado.\"\"\"\n",
        "        token = self.token_actual()\n",
        "        if not token:\n",
        "            raise SyntaxError(f\"Se esperaba {tipo_esperado}, pero se encontró el final\")\n",
        "\n",
        "        tipo, valor, pos = token\n",
        "        if tipo != tipo_esperado:\n",
        "            raise SyntaxError(\n",
        "                f\"Se esperaba {tipo_esperado}, pero se encontró {tipo} en posición {pos}\"\n",
        "            )\n",
        "\n",
        "        self.pos += 1\n",
        "        return valor\n",
        "\n",
        "    def parse_E(self):\n",
        "        \"\"\"E -> T E'\"\"\"\n",
        "        nodo = self.parse_T()\n",
        "        return self.parse_E_prima(nodo)\n",
        "\n",
        "    def parse_E_prima(self, izquierda):\n",
        "        \"\"\"E' -> + T E' | - T E' | ε\"\"\"\n",
        "        token = self.token_actual()\n",
        "        if token and token[0] in ['SUMA', 'RESTA']:\n",
        "            operador = '+' if token[0] == 'SUMA' else '-'\n",
        "            self.consumir(token[0])\n",
        "            derecha = self.parse_T()\n",
        "            nodo = OperacionBinaria(izquierda, operador, derecha)\n",
        "            return self.parse_E_prima(nodo)  # Asociatividad izquierda\n",
        "        return izquierda  # ε (epsilon)\n",
        "\n",
        "    def parse_T(self):\n",
        "        \"\"\"T -> F T'\"\"\"\n",
        "        nodo = self.parse_F()\n",
        "        return self.parse_T_prima(nodo)\n",
        "\n",
        "    def parse_T_prima(self, izquierda):\n",
        "        \"\"\"T' -> * F T' | / F T' | ε\"\"\"\n",
        "        token = self.token_actual()\n",
        "        if token and token[0] in ['MULT', 'DIV']:\n",
        "            operador = '*' if token[0] == 'MULT' else '/'\n",
        "            self.consumir(token[0])\n",
        "            derecha = self.parse_F()\n",
        "            nodo = OperacionBinaria(izquierda, operador, derecha)\n",
        "            return self.parse_T_prima(nodo)  # Asociatividad izquierda\n",
        "        return izquierda  # ε (epsilon)\n",
        "\n",
        "    def parse_F(self):\n",
        "        \"\"\"F -> ( E ) | numero | id\"\"\"\n",
        "        token = self.token_actual()\n",
        "\n",
        "        if not token:\n",
        "            raise SyntaxError(\"Se esperaba un factor pero se encontró el final\")\n",
        "\n",
        "        tipo, valor, pos = token\n",
        "\n",
        "        if tipo == 'LPAREN':\n",
        "            self.consumir('LPAREN')\n",
        "            nodo = self.parse_E()\n",
        "            self.consumir('RPAREN')\n",
        "            return nodo\n",
        "        elif tipo == 'NUMERO':\n",
        "            self.consumir('NUMERO')\n",
        "            return Numero(valor)\n",
        "        elif tipo == 'ID':\n",
        "            self.consumir('ID')\n",
        "            return Variable(valor)\n",
        "        else:\n",
        "            raise SyntaxError(f\"Token inesperado: {tipo} en posición {pos}\")\n",
        "\n",
        "    def parse(self):\n",
        "        \"\"\"Punto de entrada del parser.\"\"\"\n",
        "        ast = self.parse_E()\n",
        "        if self.pos != len(self.tokens):\n",
        "            tipo, valor, pos = self.tokens[self.pos]\n",
        "            raise SyntaxError(f\"Tokens adicionales después del final: {tipo} en posición {pos}\")\n",
        "        return ast\n",
        "\n",
        "# Pruebas\n",
        "print(\"=\"*70)\n",
        "print(\"PARSER DE DESCENSO RECURSIVO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "pruebas = [\n",
        "    (\"3 + 4\", {}),\n",
        "    (\"10 * 2 + 5\", {}),\n",
        "    (\"(4 + 5) * 3\", {}),\n",
        "    (\"x + y * 2\", {'x': 5, 'y': 3}),\n",
        "]\n",
        "\n",
        "for expr, vars in pruebas:\n",
        "    print(f\"\\nExpresión: {expr}\")\n",
        "    if vars:\n",
        "        print(f\"Variables: {vars}\")\n",
        "\n",
        "    try:\n",
        "        tokens = tokenizar(expr)\n",
        "        parser = ParserDescensoRecursivo(tokens)\n",
        "        ast = parser.parse()\n",
        "        resultado = ast.evaluar(vars)\n",
        "\n",
        "        print(f\"AST: {ast}\")\n",
        "        print(f\"Resultado: {resultado}\")\n",
        "        print(\"✓ Parsing exitoso\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ El parser descendente construye el AST de arriba hacia abajo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yixDbJbcV7ZZ"
      },
      "source": [
        "## Ejercicio 12: Tabla de Análisis LL(1)\n",
        "\n",
        "**Objetivo:** Construir una tabla LL(1) y usarla para parsing.\n",
        "\n",
        "Gramática:\n",
        "```\n",
        "E -> T E'\n",
        "E' -> + T E' | ε\n",
        "T -> F T'\n",
        "T' -> * F T' | ε\n",
        "F -> ( E ) | id\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk7hWurCV7ZZ",
        "outputId": "49db4bb0-3513-40ad-caee-42113e947863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TABLA DE ANÁLISIS LL(1)\n",
            "======================================================================\n",
            "\n",
            "        id          (                       )           *           +           \n",
            "--------------------------------------------------------------------------------\n",
            "E       T E'        T E'                                                        \n",
            "E'                              ε           ε                       + T E'      \n",
            "T       F T'        F T'                                                        \n",
            "T'                              ε           ε           * F T'      ε           \n",
            "F       id          ( E )                                                       \n",
            "\n",
            "======================================================================\n",
            "TRAZA DE ANÁLISIS PARA: id + id * id\n",
            "======================================================================\n",
            "\n",
            "==========================================================================================\n",
            "Pila                           Entrada                   Acción\n",
            "------------------------------------------------------------------------------------------\n",
            "E                              id + id * id              E -> T E'\n",
            "T E'                           id + id * id              T -> F T'\n",
            "F T' E'                        id + id * id              F -> id\n",
            "id T' E'                       id + id * id              Match 'id'\n",
            "T' E'                          + id * id                 T' -> ε\n",
            "E'                             + id * id                 E' -> + T E'\n",
            "+ T E'                         + id * id                 Match '+'\n",
            "T E'                           id * id                   T -> F T'\n",
            "F T' E'                        id * id                   F -> id\n",
            "id T' E'                       id * id                   Match 'id'\n",
            "T' E'                          * id                      T' -> * F T'\n",
            "* F T' E'                      * id                      Match '*'\n",
            "F T' E'                        id                        F -> id\n",
            "id T' E'                       id                        Match 'id'\n",
            "T' E'                                                    T' -> ε\n",
            "E'                                                       E' -> ε\n",
            "                                                         Match ''\n",
            "\n",
            "✓ El parser LL(1) usa la tabla para decidir qué producción aplicar\n"
          ]
        }
      ],
      "source": [
        "# Tabla LL(1): tabla[no_terminal][terminal] = producción\n",
        "tabla_ll1 = {\n",
        "    'E': {\n",
        "        'id': \"T E'\",\n",
        "        '(': \"T E'\",\n",
        "    },\n",
        "    \"E'\": {\n",
        "        '+': \"+ T E'\",\n",
        "        ')': \"ε\",\n",
        "        '': \"ε\",\n",
        "    },\n",
        "    'T': {\n",
        "        'id': \"F T'\",\n",
        "        '(': \"F T'\",\n",
        "    },\n",
        "    \"T'\": {\n",
        "        '+': \"ε\",\n",
        "        '*': \"* F T'\",\n",
        "        ')': \"ε\",\n",
        "        '': \"ε\",\n",
        "    },\n",
        "    'F': {\n",
        "        'id': \"id\",\n",
        "        '(': \"( E )\",\n",
        "    }\n",
        "}\n",
        "\n",
        "def mostrar_tabla_ll1(tabla):\n",
        "    \"\"\"Imprime la tabla LL(1) de forma legible.\"\"\"\n",
        "    terminales = set()\n",
        "    for producciones in tabla.values():\n",
        "        terminales.update(producciones.keys())\n",
        "    terminales = sorted(terminales, key=lambda x: (x != 'id', x != '(', x))\n",
        "\n",
        "    print(f\"{'':8}\", end=\"\")\n",
        "    for t in terminales:\n",
        "        print(f\"{t:12}\", end=\"\")\n",
        "    print()\n",
        "    print(\"-\" * (8 + 12 * len(terminales)))\n",
        "\n",
        "    for nt in tabla:\n",
        "        print(f\"{nt:8}\", end=\"\")\n",
        "        for t in terminales:\n",
        "            prod = tabla[nt].get(t, '')\n",
        "            print(f\"{prod:12}\", end=\"\")\n",
        "        print()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TABLA DE ANÁLISIS LL(1)\")\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "mostrar_tabla_ll1(tabla_ll1)\n",
        "\n",
        "# Parser dirigido por tabla\n",
        "def parser_ll1_tabla(entrada, tabla, simbolo_inicial='E'):\n",
        "    \"\"\"\n",
        "    Parser LL(1) dirigido por tabla.\n",
        "    \"\"\"\n",
        "    # Preparar entrada\n",
        "    tokens_entrada = entrada + ['']\n",
        "    pila = ['', simbolo_inicial]\n",
        "    i = 0  # Índice en la entrada\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{'Pila':<30} {'Entrada':<25} {'Acción'}\")\n",
        "    print(\"-\" * 90)\n",
        "\n",
        "    while len(pila) > 0:\n",
        "        tope = pila[-1]\n",
        "        actual = tokens_entrada[i]\n",
        "\n",
        "        # Mostrar estado\n",
        "        pila_str = ' '.join(reversed(pila))\n",
        "        entrada_str = ' '.join(tokens_entrada[i:])\n",
        "\n",
        "        if tope == ' and actual == ':\n",
        "            print(f\"{pila_str:<30} {entrada_str:<25} ACEPTAR\")\n",
        "            return True\n",
        "\n",
        "        elif tope == actual:\n",
        "            # Match: consumir terminal\n",
        "            print(f\"{pila_str:<30} {entrada_str:<25} Match '{tope}'\")\n",
        "            pila.pop()\n",
        "            i += 1\n",
        "\n",
        "        elif tope in tabla and actual in tabla[tope]:\n",
        "            # Expandir no-terminal\n",
        "            produccion = tabla[tope][actual]\n",
        "            print(f\"{pila_str:<30} {entrada_str:<25} {tope} -> {produccion}\")\n",
        "            pila.pop()\n",
        "\n",
        "            if produccion != 'ε':\n",
        "                # Agregar producción a la pila (en orden inverso)\n",
        "                simbolos = produccion.split()\n",
        "                for simbolo in reversed(simbolos):\n",
        "                    pila.append(simbolo)\n",
        "\n",
        "        else:\n",
        "            print(f\"{pila_str:<30} {entrada_str:<25} ERROR\")\n",
        "            return False\n",
        "\n",
        "    return False\n",
        "\n",
        "# Prueba\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAZA DE ANÁLISIS PARA: id + id * id\")\n",
        "print(\"=\"*70)\n",
        "resultado = parser_ll1_tabla(['id', '+', 'id', '*', 'id'], tabla_ll1)\n",
        "print(\"\\n✓ El parser LL(1) usa la tabla para decidir qué producción aplicar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrQZF_kfV7ZZ"
      },
      "source": [
        "## Ejercicio 13: Conceptos de Análisis Ascendente\n",
        "\n",
        "**Objetivo:** Comprender las operaciones shift y reduce.\n",
        "\n",
        "**Análisis Ascendente:** Construye el árbol desde las hojas hacia la raíz.\n",
        "\n",
        "**Operaciones principales:**\n",
        "- **SHIFT:** Desplazar (push) un token de la entrada a la pila\n",
        "- **REDUCE:** Reducir (pop) símbolos de la pila usando una producción\n",
        "- **ACCEPT:** Aceptar la cadena\n",
        "- **ERROR:** Rechazar la cadena\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBjgIgEhV7ZZ",
        "outputId": "9cf0ec6c-f36b-43e8-fab7-0d5171dd09aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ANÁLISIS ASCENDENTE: SHIFT-REDUCE\n",
            "======================================================================\n",
            "\n",
            "CONCEPTO FUNDAMENTAL:\n",
            "====================\n",
            "El parser ascendente lee tokens de izquierda a derecha y:\n",
            "1. DESPLAZA (shift) tokens a una pila\n",
            "2. Cuando reconoce el lado derecho de una producción en la pila,\n",
            "   lo REDUCE al no-terminal correspondiente\n",
            "3. Continúa hasta reducir todo al símbolo inicial\n",
            "\n",
            "Ejemplo: Parsear \"id + id\" con gramática E -> E + E | id\n",
            "\n",
            "Paso  Pila           Entrada      Acción\n",
            "----  -------------  -----------  -------------------------\n",
            "1     $              id + id $    shift\n",
            "2     $ id           + id $       reduce (id -> E)\n",
            "3     $ E            + id $       shift\n",
            "4     $ E +          id $         shift\n",
            "5     $ E + id       $            reduce (id -> E)\n",
            "6     $ E + E        $            reduce (E + E -> E)\n",
            "7     $ E            $            ACCEPT\n",
            "\n",
            "VENTAJAS del análisis ascendente:\n",
            "✓ Maneja gramáticas con recursión izquierda\n",
            "✓ Más potente que el análisis descendente\n",
            "✓ Usado por la mayoría de generadores (YACC, Bison)\n",
            "\n",
            "DESVENTAJAS:\n",
            "✗ Más complejo de entender e implementar\n",
            "✗ Requiere tablas de análisis complejas\n",
            "✗ Más difícil de depurar manualmente\n",
            "\n",
            "======================================================================\n",
            "PREGUNTA: ¿Cuándo hacer SHIFT y cuándo REDUCE?\n",
            "======================================================================\n",
            "\n",
            "Esta es la pregunta clave del análisis ascendente.\n",
            "La respuesta depende del tipo de parser:\n",
            "\n",
            "- Parser LR(0): Usa solo la pila (estados)\n",
            "- Parser SLR: Usa pila + 1 token de lookahead\n",
            "- Parser LALR: Versión optimizada de LR(1)\n",
            "- Parser LR(1): Usa pila + k tokens de lookahead\n",
            "\n",
            "Todos usan TABLAS DE ANÁLISIS preconstruidas.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"ANÁLISIS ASCENDENTE: SHIFT-REDUCE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\"\"\n",
        "CONCEPTO FUNDAMENTAL:\n",
        "====================\n",
        "El parser ascendente lee tokens de izquierda a derecha y:\n",
        "1. DESPLAZA (shift) tokens a una pila\n",
        "2. Cuando reconoce el lado derecho de una producción en la pila,\n",
        "   lo REDUCE al no-terminal correspondiente\n",
        "3. Continúa hasta reducir todo al símbolo inicial\n",
        "\n",
        "Ejemplo: Parsear \"id + id\" con gramática E -> E + E | id\n",
        "\n",
        "Paso  Pila           Entrada      Acción\n",
        "----  -------------  -----------  -------------------------\n",
        "1     $              id + id $    shift\n",
        "2     $ id           + id $       reduce (id -> E)\n",
        "3     $ E            + id $       shift\n",
        "4     $ E +          id $         shift\n",
        "5     $ E + id       $            reduce (id -> E)\n",
        "6     $ E + E        $            reduce (E + E -> E)\n",
        "7     $ E            $            ACCEPT\n",
        "\n",
        "VENTAJAS del análisis ascendente:\n",
        "✓ Maneja gramáticas con recursión izquierda\n",
        "✓ Más potente que el análisis descendente\n",
        "✓ Usado por la mayoría de generadores (YACC, Bison)\n",
        "\n",
        "DESVENTAJAS:\n",
        "✗ Más complejo de entender e implementar\n",
        "✗ Requiere tablas de análisis complejas\n",
        "✗ Más difícil de depurar manualmente\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PREGUNTA: ¿Cuándo hacer SHIFT y cuándo REDUCE?\")\n",
        "print(\"=\"*70)\n",
        "print(\"\"\"\n",
        "Esta es la pregunta clave del análisis ascendente.\n",
        "La respuesta depende del tipo de parser:\n",
        "\n",
        "- Parser LR(0): Usa solo la pila (estados)\n",
        "- Parser SLR: Usa pila + 1 token de lookahead\n",
        "- Parser LALR: Versión optimizada de LR(1)\n",
        "- Parser LR(1): Usa pila + k tokens de lookahead\n",
        "\n",
        "Todos usan TABLAS DE ANÁLISIS preconstruidas.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gZFZpb1V7ZZ"
      },
      "source": [
        "## Ejercicio 14: Identificación de Handles\n",
        "\n",
        "**Objetivo:** Aprender a identificar el \"handle\" (mango) para reducir.\n",
        "\n",
        "**Handle:** Subcadena que coincide con el lado derecho de una producción y cuya reducción nos acerca al símbolo inicial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T37J2WPV7ZZ",
        "outputId": "fa41e981-7da6-411a-e3ad-82eb934ef8a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "IDENTIFICACIÓN DE HANDLES\n",
            "======================================================================\n",
            "\n",
            "Gramática:\n",
            "  E -> E + T\n",
            "  E -> T\n",
            "  T -> T * F\n",
            "  T -> F\n",
            "  F -> ( E )\n",
            "  F -> id\n",
            "\n",
            "\n",
            "Ejemplos de identificación de handles:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Ejemplo 1:\n",
            "  Forma sentencial: E + T * id\n",
            "  Handle: id\n",
            "  Producción: F -> id\n",
            "  Explicación: id se puede reducir a F\n",
            "\n",
            "Ejemplo 2:\n",
            "  Forma sentencial: E + T * F\n",
            "  Handle: T * F\n",
            "  Producción: T -> T * F\n",
            "  Explicación: T * F se reduce a T\n",
            "\n",
            "Ejemplo 3:\n",
            "  Forma sentencial: E + T\n",
            "  Handle: E + T\n",
            "  Producción: E -> E + T\n",
            "  Explicación: E + T se reduce a E\n",
            "\n",
            "======================================================================\n",
            "REGLA GENERAL: El handle es la subcadena más a la derecha\n",
            "que se puede reducir en una derivación rightmost en reversa.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"IDENTIFICACIÓN DE HANDLES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "gramatica = \"\"\"\n",
        "Gramática:\n",
        "  E -> E + T\n",
        "  E -> T\n",
        "  T -> T * F\n",
        "  T -> F\n",
        "  F -> ( E )\n",
        "  F -> id\n",
        "\"\"\"\n",
        "print(gramatica)\n",
        "\n",
        "# Ejercicio: identificar handles\n",
        "ejemplos = [\n",
        "    {\n",
        "        'forma_sentencial': 'E + T * id',\n",
        "        'handle': 'id',\n",
        "        'produccion': 'F -> id',\n",
        "        'explicacion': 'id se puede reducir a F'\n",
        "    },\n",
        "    {\n",
        "        'forma_sentencial': 'E + T * F',\n",
        "        'handle': 'T * F',\n",
        "        'produccion': 'T -> T * F',\n",
        "        'explicacion': 'T * F se reduce a T'\n",
        "    },\n",
        "    {\n",
        "        'forma_sentencial': 'E + T',\n",
        "        'handle': 'E + T',\n",
        "        'produccion': 'E -> E + T',\n",
        "        'explicacion': 'E + T se reduce a E'\n",
        "    },\n",
        "]\n",
        "\n",
        "print(\"\\nEjemplos de identificación de handles:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for i, ej in enumerate(ejemplos, 1):\n",
        "    print(f\"\\nEjemplo {i}:\")\n",
        "    print(f\"  Forma sentencial: {ej['forma_sentencial']}\")\n",
        "    print(f\"  Handle: {ej['handle']}\")\n",
        "    print(f\"  Producción: {ej['produccion']}\")\n",
        "    print(f\"  Explicación: {ej['explicacion']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"REGLA GENERAL: El handle es la subcadena más a la derecha\")\n",
        "print(\"que se puede reducir en una derivación rightmost en reversa.\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEFN-JNsY8ip"
      },
      "source": [
        "### Próximos Pasos\n",
        "1. Estudiar análisis semántico\n",
        "2. Aprender sobre generación de código\n",
        "3. Implementar optimizaciones\n",
        "4. Crear un lenguaje completo\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}